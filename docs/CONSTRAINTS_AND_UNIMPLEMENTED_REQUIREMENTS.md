# ADAPTIVE AI LEARN - CONSTRAINTS AND UNIMPLEMENTED FUNCTIONAL REQUIREMENTS

**Project:** Adaptive AI Learn (Personalized Learning Content with AI-Adaptive Features)  
**Academic Year:** 2025-2026  
**Reporting Date:** January 15, 2026  
**Document Version:** 1.0  
**Status:** Final Report

---

## TABLE OF CONTENTS

1. Unimplemented / Incomplete Functional Requirements
2. Constraints Section
3. GitHub Repository Links
4. Lessons Learned & Recommendations for Future Phases

---

---

## 1. UNIMPLEMENTED / INCOMPLETE FUNCTIONAL REQUIREMENTS

### 1.1 Fully Unimplemented Features

This section documents features that were initially planned (in SRS/Requirements) but were not implemented during the MVP development phase.

#### 1.1.1 FR12 (Partial) — Advanced Content Scheduling with Calendar Integration

**Feature Description:**
- Teachers to schedule lessons and assignments with calendar visualization
- Automated deadline reminders with timezone conversion
- Conflict detection with school holidays and calendar events
- Integration with Google Calendar / Microsoft Outlook

**Implemented Scope:**
- ✅ Basic lesson assignment creation
- ✅ Simple deadline tracking
- ❌ Calendar UI visualization
- ❌ Timezone conversion
- ❌ Holiday/conflict detection
- ❌ External calendar integration (Google/Outlook)

**Reason for Non-Implementation:**
- **Time Constraint:** Full calendar integration requires 2-3 weeks of frontend development + API integration testing
- **Complexity vs. MVP Priority:** Core functionality (assignment creation and tracking) completed; visual calendar is enhancement
- **External Dependencies:** Google Calendar/Outlook APIs require additional OAuth scopes and compliance review
- **Team Bandwidth:** Development team prioritized core AI and assessment features over UI enhancements

**Related Constraint:** Time Constraints (Section 2.3), Team Competency Constraints (Section 2.9)

**Planned for Phase 2:** Yes — Scheduled for Integration Testing phase with dedicated frontend developer allocation

**Impact Assessment:**
- **Functional Impact:** Low — Teachers can still assign deadlines; visual calendar is convenience feature
- **User Experience Impact:** Medium — Some teacher workflows require manual calendar management
- **Business Impact:** Low — Feature not critical to MVP success; can be added post-launch

---

#### 1.1.2 FR22 (Partial) — Separate Speaking Module with Advanced Features

**Feature Description:**
- Dedicated speaking module with pronunciation analysis
- Advanced speech recognition (beyond voice input)
- Phonetic feedback and accent analysis
- Real-time speech waveform visualization
- Comparison with native speaker audio samples

**Implemented Scope:**
- ✅ Voice input capture (basic)
- ✅ Text-to-speech for listening practice
- ✅ Audio file submission/storage
- ❌ Pronunciation scoring engine
- ❌ Phonetic analysis
- ❌ Speech waveform visualization
- ❌ Accent analysis algorithms
- ❌ Native speaker comparison

**Reason for Non-Implementation:**
- **Technology Constraint:** Advanced speech recognition (pronunciation + accent analysis) requires:
  - Specialized ML models (not available in TensorFlow.js)
  - High computational resources (GPU-based processing)
  - Integration with third-party APIs (Google Cloud Speech-to-Text Advanced, Azure Speech Services)
- **Cost Constraint:** These APIs require paid subscriptions; MVP budget limited to free tier services
- **Team Competency Constraint:** ML expertise required for speech processing; team lacked specialized training in phonetic analysis
- **Time Constraint:** Implementation would require 4-6 weeks of research, model selection, and testing

**Related Constraints:** Budget Constraints (Section 2.2), Hardware Constraints (Section 2.4), Team Competency Constraints (Section 2.9), Technology Stack Constraints

**Planned for Phase 2:** Yes — Planned for late Phase 2 with external consultant for speech ML expertise

**Workaround Implemented:**
- Voice recording capability provided
- Teachers can manually review audio submissions
- Basic audio playback and transcription via Google Cloud Speech-to-Text (free tier, limited requests)

**Impact Assessment:**
- **Functional Impact:** Medium — Speaking practice available but without automated analysis
- **User Experience Impact:** Medium — Students must wait for teacher feedback on pronunciation
- **Business Impact:** Medium — Speaking module less competitive vs. premium platforms; acceptable for MVP

---

#### 1.1.3 FR23 (Partial) — Multi-Modal Learning: Comprehensive Listening Module

**Feature Description:**
- Advanced listening comprehension exercises
- Adaptive speed adjustment (slow/normal/fast speech)
- Transcript reveal strategies (none → highlights → full)
- Real-time listening analytics (pause frequency, replay count)
- Dialogue-based lessons with speaker switching

**Implemented Scope:**
- ✅ Audio file hosting and playback
- ✅ Basic comprehension questions after audio
- ❌ Speed adjustment controls
- ❌ Adaptive transcript reveal
- ❌ Advanced listening analytics
- ❌ Dialogue switching visualization

**Reason for Non-Implementation:**
- **Time Constraint:** UI implementation for listening controls + analytics dashboard = 3-4 weeks
- **Complexity:** Backend logic for adaptive transcript reveal adds complexity to content delivery system
- **Analytics Infrastructure:** Real-time listening analytics requires new database schema and processing pipeline
- **Content Creation:** Limited pre-recorded dialogue content available for launch
- **Prioritization:** Reading and writing modules prioritized; listening treated as secondary for MVP

**Related Constraints:** Time Constraints (Section 2.3), Team Competency Constraints (Section 2.9)

**Planned for Phase 2:** Yes — Scheduled after initial user feedback on reading/writing modules

**Impact Assessment:**
- **Functional Impact:** Low-Medium — Basic listening practice available without advanced features
- **User Experience Impact:** Low — Students can still engage with audio content
- **Business Impact:** Low — Feature not critical to initial launch; can be iterated based on feedback

---

#### 1.1.4 FR15 (Partial) — SMS and Push Notifications

**Feature Description:**
- SMS/text message notifications for critical alerts
- Native mobile push notifications
- Configurable notification channels (email, SMS, push, in-app)
- Do-Not-Disturb scheduling per user
- Notification analytics (open rate, click-through rate)

**Implemented Scope:**
- ✅ Email notifications (working)
- ✅ In-app notifications via bell icon
- ❌ SMS notifications
- ❌ Native mobile push notifications
- ❌ Do-Not-Disturb scheduling
- ❌ Notification analytics dashboard

**Reason for Non-Implementation:**
- **Cost Constraint:** SMS requires paid service (Twilio, AWS SNS); budget allocated to other services
- **Mobile Platform Constraint:** Mobile app not in MVP scope; push notifications require native mobile development
- **Complexity:** Push notification infrastructure requires:
  - Service worker implementation
  - Firebase Cloud Messaging setup
  - Device token management
  - Multi-platform compliance
- **Time Constraint:** Estimated 2-3 weeks for infrastructure setup and testing

**Related Constraints:** Budget Constraints (Section 2.2), Platform Constraints (Section 2.5), Time Constraints (Section 2.3)

**Workaround Implemented:**
- Email notifications fully functional for all alert types
- In-app bell notifications (browser tab notifications via Web Notifications API)
- Manual notification preferences UI allows future SMS/push integration

**Impact Assessment:**
- **Functional Impact:** Low — Email + in-app notifications cover most use cases
- **User Experience Impact:** Medium — Mobile users may miss time-sensitive alerts without push
- **Business Impact:** Low — Email sufficient for MVP; mobile notifications planned for Phase 2

---

#### 1.1.5 FR11 (Partial) — Advanced Multi-Language & Cultural Adaptation

**Feature Description:**
- Support for 15+ languages with full localization
- Cultural adaptation of content, images, and examples
- Right-to-left (RTL) language support (Arabic, Hebrew)
- Cultural diversity review workflow
- Locale-specific content variants (US English vs. British English)

**Implemented Scope:**
- ✅ English (primary language)
- ✅ Spanish (basic UI localization)
- ✅ Turkish (in progress)
- ⚠️ Language picker in settings
- ❌ 15+ language support
- ❌ RTL language rendering
- ❌ Cultural adaptation workflow
- ❌ Regional content variants

**Reason for Non-Implementation:**
- **Time Constraint:** Each language requires 1-2 weeks of translation + testing
- **Content Constraint:** Only 3 languages planned for MVP based on market focus
- **Team Competency:** Limited translation resources; outsourced to contractors for initial languages
- **RTL Support:** Requires CSS redesign and special testing; deferred to Phase 2
- **Cultural Review:** Formal process would require external stakeholders not available during MVP

**Related Constraints:** Time Constraints (Section 2.3), Budget Constraints (Section 2.2), Team Competency Constraints (Section 2.9)

**Planned for Phase 2:** Yes — Additional languages based on user demand data

**Impact Assessment:**
- **Functional Impact:** Low — Primary markets covered with English/Spanish/Turkish
- **User Experience Impact:** Low-Medium — Non-supported language users see English fallback
- **Business Impact:** Medium — Limits market expansion until more languages available

---

#### 1.1.6 FR12 (Partial) — LMS Integration with Grade Sync

**Feature Description:**
- Synchronize with Canvas, Blackboard, Google Classroom, Moodle
- Two-way grade synchronization
- Enrollment syncing via LTI 1.3
- Real-time roster updates
- Automated grade posting to external LMS

**Implemented Scope:**
- ✅ Grade export to CSV/PDF (manual download)
- ✅ Student roster upload (manual CSV import)
- ❌ Canvas/Blackboard API integration
- ❌ LTI 1.3 implementation
- ❌ Real-time sync
- ❌ Two-way grade sync

**Reason for Non-Implementation:**
- **Time Constraint:** Each LMS integration requires 2-3 weeks of development + testing
- **Integration Complexity:** LTI 1.3 implementation is non-trivial; requires OAuth 2.0 + JWT handling
- **Security Requirements:** LMS integrations require compliance with institutional standards (FERPA, etc.)
- **Testing Burden:** Each LMS integration requires separate testing environment
- **Priority:** Manual import/export sufficient for MVP; automated sync deferred

**Related Constraints:** Time Constraints (Section 2.3), Maintenance & Sustainability (Section 2.8)

**Planned for Phase 2:** Yes — Canvas integration prioritized based on market demand

**Impact Assessment:**
- **Functional Impact:** Medium — Manual grade export/import works but not automated
- **User Experience Impact:** Medium — Teachers must manually sync grades; adds workflow friction
- **Business Impact:** Medium — Reduces adoption in institutions requiring LMS integration

---

#### 1.1.7 FR7 (Partial) — Advanced NLP for Open-Ended Responses

**Feature Description:**
- Semantic analysis of essay responses
- Multi-dimensional rubric scoring (Clarity, Accuracy, Completeness, Organization)
- Plagiarism detection
- Grammar and style feedback
- Conceptual error detection with remediation suggestions
- Confidence scoring for automated feedback

**Implemented Scope:**
- ✅ Basic keyword matching (rule-based)
- ✅ Simple automated feedback
- ✅ Manual teacher review capability
- ✅ Spelling/grammar checking (basic)
- ❌ Semantic analysis (advanced)
- ❌ Multi-dimensional rubric scoring
- ❌ Plagiarism detection
- ❌ Conceptual error detection
- ❌ Confidence scoring for automation

**Reason for Non-Implementation:**
- **Technology Constraint:** Advanced NLP requires:
  - State-of-the-art models (BERT, GPT-based embeddings)
  - High computational resources (GPU-based inference)
  - Large training datasets specific to domain
- **Team Competency Constraint:** Advanced NLP expertise not available on team
- **Cost Constraint:** Using commercial NLP APIs (OpenAI, Hugging Face) requires paid subscription
- **Time Constraint:** Research + implementation + testing = 6-8 weeks
- **Data Privacy Constraint:** Using external APIs raises data privacy concerns (student responses sent to third parties)

**Related Constraints:** Team Competency Constraints (Section 2.9), Budget Constraints (Section 2.2), Data Privacy Constraints (Section 2.6), Technology Stack Constraints

**Planned for Phase 2:** Yes — With external ML consultant and approved vendor for NLP services

**Current Workaround:**
- Teachers can manually review open-ended responses
- System provides basic grammar/spelling feedback
- Confidence-based routing sends low-confidence responses to teacher review

**Impact Assessment:**
- **Functional Impact:** Medium — Automated grading works for simple responses; teacher required for complex answers
- **User Experience Impact:** Medium — Students wait for teacher feedback on essays
- **Business Impact:** Medium — Reduces competitive advantage vs. premium platforms with advanced NLP

---

#### 1.1.8 FR16 (Partial) — Advanced ML Model Retraining & Monitoring

**Feature Description:**
- Automated model retraining on scheduled basis (daily/weekly)
- A/B testing framework for model comparison
- Automated model validation and deployment
- Real-time model performance monitoring
- Automated rollback on performance degradation
- Model explainability and feature importance analysis
- Fairness/bias detection and mitigation

**Implemented Scope:**
- ✅ Manual model retraining (on-demand)
- ✅ Holdout validation during training
- ✅ Basic performance metrics (accuracy, F1 score)
- ✅ Manual rollback capability
- ❌ Automated scheduled retraining
- ❌ A/B testing framework
- ❌ Automated deployment pipeline
- ❌ Real-time monitoring dashboard
- ❌ Automated rollback
- ❌ Explainability analysis
- ❌ Fairness/bias detection

**Reason for Non-Implementation:**
- **Team Competency Constraint:** ML Ops expertise required; team has data scientists but limited DevOps expertise
- **Infrastructure Constraint:** Automated ML pipeline requires dedicated infrastructure (ML Ops tools like MLflow, Kubeflow)
- **Time Constraint:** Building ML Ops infrastructure = 4-6 weeks
- **Cost Constraint:** ML Ops tools require paid cloud services or infrastructure investment
- **Complexity:** Fairness/bias detection requires specialized knowledge and external auditing

**Related Constraints:** Team Competency Constraints (Section 2.9), Hardware & Infrastructure Constraints (Section 2.4), Budget Constraints (Section 2.2)

**Planned for Phase 2:** Yes — ML Ops infrastructure planned post-launch

**Impact Assessment:**
- **Functional Impact:** Low — Models can be manually retrained; production use is manual process
- **Operational Impact:** Medium — Operations team must manually manage retraining cycles
- **Business Impact:** Low-Medium — Risk of model staleness; manual process scales poorly

---

### 1.2 Partially Implemented Features

This section documents features that were implemented but with reduced scope compared to original requirements.

#### 1.2.1 FR4 — Dynamic Learning Path Generation

**Original Requirement:**
- Real-time path generation based on student performance
- Multi-criteria optimization (balance challenge, interest, prerequisites)
- Adaptive path branching (multiple valid next steps)
- Path deviation tracking and explanation

**Current Implementation:**
- ✅ Path generation works correctly
- ✅ Single-path recommendation (deterministic)
- ✅ Performance-based difficulty adjustment
- ❌ Multi-path recommendations (branches not shown)
- ❌ Path optimization on secondary criteria (interest, learning style)
- ❌ Deviation explanations to students

**Reason for Reduced Scope:**
- **Time Constraint:** Multi-path optimization requires additional algorithm design + testing
- **Complexity:** Balancing multiple objectives (challenge, interest, prerequisites) adds algorithmic complexity
- **UI/UX Complexity:** Presenting multiple path options to students requires careful design
- **Validation:** Multi-path system requires more extensive testing

**Recommendation:** ✅ Current implementation sufficient for MVP; multi-path feature can be added in Phase 2 based on user feedback

---

#### 1.2.2 FR10 — Teacher Dashboard & Analytics

**Original Requirement:**
- Real-time class analytics with 10+ metrics
- Predictive analytics (at-risk student detection)
- Actionable recommendations for intervention
- Custom report building
- Export to multiple formats (PDF, CSV, Excel, PowerPoint)

**Current Implementation:**
- ✅ Real-time dashboard with 8 core metrics
- ✅ At-risk student flagging (rule-based, not predictive ML)
- ✅ Intervention recommendations (system-generated)
- ✅ PDF/CSV export
- ❌ Advanced analytics (10+ metrics)
- ❌ Predictive ML models for at-risk detection
- ❌ Custom report builder
- ❌ PowerPoint export

**Reason for Reduced Scope:**
- **Time Constraint:** Custom report builder = 2-3 weeks of development
- **Complexity:** Predictive at-risk detection requires separate ML model training
- **Scope Creep:** Advanced analytics features deferred to maintain MVP timeline

**Recommendation:** ✅ Current dashboard provides essential teacher functionality; advanced features in Phase 2

---

### 1.3 Features Deferred to Future Phases

The following features were intentionally deferred from MVP development:

| Feature | Original FR | Phase 2+ | Reason |
|---------|-------------|---------|--------|
| Advanced Student Portfolio | New | Phase 2 | Requires portfolio platform integration |
| Gamification (Advanced Levels, Leaderboards) | FR3 (Partial) | Phase 3 | Requires additional UX design + A/B testing |
| Live Tutor Integration (Video/Chat) | Out of scope | Phase 2 | Requires WebSocket infrastructure + video platform |
| Native Mobile App | Out of scope | Phase 2 | Requires separate iOS/Android development |
| Biometric Authentication | Out of scope | Phase 3 | Not MVP priority |
| Voice-based Course Authoring | Out of scope | Phase 3 | Specialized feature; low priority |
| Peer Collaboration Tools | Out of scope | Phase 3 | Requires social network infrastructure |
| Blockchain-based Credentials | Out of scope | Phase 3+ | Emerging technology; maturity not ready |

---

---

## 2. CONSTRAINTS SECTION

### 2.1 Time Constraints

#### 2.1.1 Description

The "Adaptive AI Learn" project was developed under an **academic semester timeline** (approximately 16 weeks from September 2025 to January 15, 2026), which significantly impacted feature scope and implementation depth.

#### 2.1.2 Impact on Project Decisions

**Semester Duration Limitation:**
- Total development time: 16 weeks (approximately 3.5 months)
- 6 team members working part-time (20-30 hours/week due to concurrent coursework)
- Effective full-time equivalent: ~3 FTE developers for 16 weeks

**Specific Decisions Made Due to Time Constraints:**

1. **Technology Stack Simplification**
   - Chose Node.js + Express over microservices architecture
   - Selected MongoDB (simpler schema design) over complex relational DB
   - Used existing libraries (TensorFlow.js, Prisma) vs. building custom ML/ORM
   - Decision Impact: Reduced learning curve and accelerated development

2. **Scope Prioritization**
   - Core features (Learning Path, Assessments, Dashboard) prioritized
   - UI/UX polish deferred
   - Advanced features (LMS integration, advanced NLP) deferred to Phase 2
   - Decision Impact: Delivered MVP on time; trade-off on feature completeness

3. **Testing Phase Timing**
   - Development Testing conducted during final 4 weeks
   - Integration Testing deferred to Phase 2
   - Decision Impact: Limited time for comprehensive integration testing; risk identified

4. **Documentation Scope**
   - Created comprehensive test documentation (THIS PROJECT)
   - Architectural diagrams finalized
   - API documentation automated (Swagger/OpenAPI)
   - Decision Impact: Excellent test documentation; some design docs still in progress

#### 2.1.3 Specific Timeline Constraints

| Phase | Duration | Constraint | Impact |
|-------|----------|-----------|--------|
| **Requirements & Design** | Weeks 1-4 | Limited time for architecture reviews | Design reviewed once; no iteration |
| **Development** | Weeks 5-12 | Part-time development with coursework | Code coverage lower than ideal (75%) |
| **Integration & Testing** | Weeks 13-14 | Only 2 weeks for integration testing | Limited cross-subsystem testing |
| **Documentation & Report** | Weeks 15-16 | Final weeks compressed | Deferred some documentation tasks |

#### 2.1.4 Mitigation Strategies Applied

- ✅ Agile methodology with 1-week sprints
- ✅ Daily standups to unblock team
- ✅ Automated testing to accelerate QA
- ✅ Clear scope definition to avoid creep
- ✅ Parallel workstream development (6 subsystems developed simultaneously)

#### 2.1.5 Residual Risks

- ⚠️ Integration Testing incomplete (Phase 2 focused area)
- ⚠️ Performance testing under realistic load deferred
- ⚠️ Security penetration testing not yet completed

---

### 2.2 Budget Constraints

#### 2.2.1 Description

The project was developed as an **academic capstone project with zero budget** (unfunded development). All software, services, and infrastructure used are either open-source, free tier, or provided by the institution.

#### 2.2.2 Budget Impact on Technology Choices

**Cloud Services - Free Tier Only:**
- ✅ MongoDB Atlas (free tier: 512 MB storage, shared cluster)
- ✅ Google OAuth (free)
- ✅ GitHub (free account)
- ✅ Netlify (free tier for frontend deployment)
- ✅ Heroku (previously free; now transitioned to alternatives)
- ❌ AWS paid services not available
- ❌ Premium NLP APIs not available (OpenAI, Azure Cognitive Services)
- ❌ Third-party LMS integrations requiring paid API access not viable

**Development Tools - Open Source Only:**
- ✅ Node.js (open-source)
- ✅ React (open-source)
- ✅ PostgreSQL/MongoDB (open-source)
- ✅ Jest, Cypress (open-source testing)
- ✅ VS Code (open-source)

**External Services Not Available Due to Budget:**
- ❌ Twilio (SMS notifications)
- ❌ SendGrid (advanced email)
- ❌ Datadog/New Relic (monitoring)
- ❌ Auth0 (advanced identity management)
- ❌ Premium speech recognition APIs
- ❌ Commercial NLP platforms

#### 2.2.3 Specific Feature Decisions

| Feature | Decision | Rationale |
|---------|----------|-----------|
| **Notifications** | Email only (free SMTP) | SMS requires paid Twilio |
| **Authentication** | OAuth + JWT (free) | Auth0 requires paid tier |
| **NLP Grading** | Basic ML locally + manual review | OpenAI API requires payment |
| **Monitoring** | Manual monitoring + logs | Datadog/New Relic require budget |
| **Speech Recognition** | Google Cloud Speech-to-Text (free tier) | Advanced APIs require payment |
| **CDN** | Netlify CDN (included free) | Cloudflare enterprise requires budget |

#### 2.2.4 Mitigation Strategies

- ✅ Selected primarily free/open-source technologies
- ✅ Used managed services free tiers (MongoDB Atlas, Google Cloud)
- ✅ Implemented manual processes for features requiring paid services
- ✅ Built extensible architecture to add paid services in Phase 2 when budget available

#### 2.2.5 Phase 2 Budget Recommendations

Recommended budget allocation for production deployment:
- Cloud infrastructure (AWS/Azure): $2,000/month
- NLP API services: $500/month
- Monitoring & observability: $300/month
- Database scaling: $200/month
- Total Phase 2 budget: ~$3,000/month

---

### 2.3 Hardware and Infrastructure Constraints

#### 2.3.1 Description

The project was developed on **standard academic computing hardware** without access to high-performance infrastructure or specialized ML training equipment.

#### 2.3.2 Hardware Limitations

**Developer Machines:**
- Typical specs: Intel i7/i9, 16 GB RAM, 512 GB SSD
- GPU availability: None (no NVIDIA GPU for accelerated ML)
- Implication: ML model training slower; limits model complexity

**Infrastructure for Deployment:**
- Free tier cloud services have resource limits
- MongoDB Atlas free tier: 512 MB storage limit
- Limited server memory for production deployment
- No dedicated GPU infrastructure for inference

#### 2.3.3 Impact on ML Implementation

| Limitation | Impact | Mitigation |
|-----------|--------|-----------|
| **No GPU** | ML training slow (hours vs. minutes) | Used TensorFlow.js (CPU-based) for simplicity |
| **Limited Memory** | Large models can't fit in memory | Selected lighter models (TensorFlow.js pre-trained) |
| **Limited Storage** | Can't store large datasets | Used sampled/aggregated data for training |
| **Network Latency** | API calls slower | Implemented local caching layer |

#### 2.3.4 Implications for Project

- ✅ Simplified ML models used (collaborative filtering, mastery modeling)
- ✅ Advanced deep learning models not feasible
- ❌ Real-time model inference might be slow under load
- ⚠️ Scalability to 1000+ concurrent users requires infrastructure upgrade

#### 2.3.5 Phase 2 Infrastructure Recommendations

- Allocate GPU infrastructure for ML training (NVIDIA A100 or similar)
- Use cloud ML platforms (AWS SageMaker, Google Vertex AI)
- Implement distributed caching (Redis cluster)
- Scale to multi-region deployment

---

### 2.4 Platform and Compatibility Constraints

#### 2.4.1 Description

The project was developed as a **web-first application**, intentionally excluding mobile-native and desktop development in the MVP scope.

#### 2.4.2 Platform Decisions

**In-Scope - Web Platform:**
- ✅ Responsive web design (mobile, tablet, desktop)
- ✅ Chrome, Firefox, Safari, Edge browsers
- ✅ Progressive Web App (PWA) capabilities
- ✅ Offline content caching (Service Workers)

**Out-of-Scope for MVP:**
- ❌ Native iOS app
- ❌ Native Android app
- ❌ Desktop application (Windows/macOS/Linux)
- ❌ Emerging platforms (VR/AR education)

#### 2.4.3 Rationale for Web-First Approach

| Constraint | Rationale | Impact |
|-----------|-----------|--------|
| **Development Time** | Native mobile requires separate codebases | MVP delivered faster with web-only |
| **Team Competency** | Team expertise in web technologies | Familiar stack accelerated development |
| **Cost** | Native apps require app store accounts & testing | Reduced cost by web-only approach |
| **Maintenance** | Single codebase easier to maintain | Reduced long-term overhead |
| **Accessibility** | Web standards (WCAG) well-established | Better accessibility on web platform |

#### 2.4.4 Current Platform Coverage

**Supported Platforms:**
- ✅ Windows (10/11) + Chrome/Firefox/Edge
- ✅ macOS + Chrome/Firefox/Safari
- ✅ Linux (Ubuntu 20.04) + Chrome/Firefox
- ✅ iOS Safari (responsive web, not native app)
- ✅ Android Chrome (responsive web, not native app)

**Excluded Platforms:**
- ❌ Native mobile apps (iOS/Android)
- ❌ Desktop applications (Electron)
- ❌ Emerging platforms (VR education)

#### 2.4.5 Mobile Experience Trade-offs

| Aspect | Status | Trade-off |
|--------|--------|-----------|
| **Responsiveness** | ✅ Fully responsive | Works on mobile but not optimized |
| **Performance** | ⚠️ Adequate | Slower on 4G; relies on caching |
| **Push Notifications** | ❌ Not available | Only email + in-app notifications |
| **Offline Access** | ✅ Partial | Cached content only |
| **Native Features** | ❌ Not used | Microphone access via browser |

#### 2.4.6 Phase 2 Platform Expansion

- React Native migration for iOS/Android (estimated 8-10 weeks)
- Platform parity with web version
- Native push notifications
- Optimized offline experience

---

### 2.5 Data and Privacy (GDPR / KVKK) Constraints

#### 2.5.1 Description

The project implemented privacy by design to comply with **GDPR (EU)**, **KVKK (Turkey)**, and **FERPA (US)** regulations. This design choice limited certain features and data usage scenarios.

#### 2.5.2 Privacy Constraints Applied

**Data Collection Limitations:**
- ✅ Only minimal required data collected (name, email, performance)
- ✅ Student response data anonymized for ML training
- ✅ No unnecessary tracking or analytics
- ❌ Cannot use full browsing history for personalization
- ❌ Cannot share data with third-party analytics platforms

**Consent-Based Processing:**
- ✅ Explicit opt-in required for data usage in model training
- ✅ Clear data usage policies provided
- ✅ Students can withdraw consent and delete data
- ✅ Data retention policies implemented (automatic deletion after 1 year inactive)

**Impact on Personalization Algorithms:**
- Reduced data available for model training
- Cannot use browsing behavior for personalization
- Cannot implement behavioral targeting
- Models trained only on explicit learning data (assessments, lesson interactions)

#### 2.5.3 Design Decisions Driven by Privacy

| Feature | Decision | Privacy Rationale |
|---------|----------|------------------|
| **Tracking** | Event-based only (no pixel tracking) | GDPR compliance |
| **NLP Grading** | Local processing, no external APIs | Data stays in-system |
| **Teacher Analytics** | Aggregated data only | Individual student privacy |
| **Model Training** | Anonymized data with consent | GDPR/KVKK/FERPA compliance |
| **Data Export** | Users can export all personal data | Right to data portability (GDPR) |
| **Data Deletion** | Users can permanently delete accounts | Right to be forgotten (GDPR) |

#### 2.5.4 Implementation Details

**Data Minimization:**
- Stored data: Student ID, name, email, learning progress, assessment scores
- Not stored: Full browsing history, keystroke logs, camera access
- Result: Smaller data footprint, lower privacy risk

**Encryption:**
- ✅ Data at rest: AES-256 encryption for sensitive fields
- ✅ Data in transit: TLS 1.3 for all connections
- ✅ Passwords: Bcrypt with 10+ salt rounds

**User Rights Implemented:**
- ✅ Right to access (download all data)
- ✅ Right to erasure (delete account + all data)
- ✅ Right to data portability (export in standard formats)
- ✅ Right to consent withdrawal (opt out of model training)

#### 2.5.5 Regulatory Compliance Status

| Regulation | Status | Evidence |
|-----------|--------|----------|
| **GDPR (EU)** | ✅ Compliant | Privacy policy, consent flows, data exports |
| **KVKK (Turkey)** | ✅ Compliant | Turkish privacy terms, data controller agreements |
| **FERPA (US)** | ✅ Compliant | Student data protection, minimal third-party sharing |
| **CCPA (California)** | ✅ Compliant | Data deletion and opt-out mechanisms |

#### 2.5.6 Phase 2 Privacy Enhancements

- Privacy impact assessments for new features
- Data minimization audit and optimization
- Enhanced consent management interface
- Privacy-preserving analytics (differential privacy techniques)

---

### 2.6 Deployment and Sharing Constraints

#### 2.6.1 Description

The project is distributed as **open-source software on GitHub**, with licensing restrictions that guided technology choices and sharing decisions.

#### 2.6.2 Open-Source Approach

**Advantages Leveraged:**
- ✅ Free to use and modify for educational purposes
- ✅ Community contributions and feedback
- ✅ Transparent development and security
- ✅ Academic integrity (auditable by faculty)

**Constraints Imposed:**
- ✅ All source code must be open-source compatible
- ✅ No proprietary dependencies allowed
- ✅ License compliance required for all libraries

#### 2.6.3 Licensing Decisions

**Project License: MIT (Permissive Open-Source)**
- Allows commercial use
- Requires attribution
- Encourages adoption and contributions

**Required Compliance with Dependency Licenses:**

| Dependency | License | Compatibility | Decision |
|-----------|---------|--------------|----------|
| **Node.js** | MIT | ✅ Compatible | Approved |
| **Express.js** | MIT | ✅ Compatible | Approved |
| **React** | MIT | ✅ Compatible | Approved |
| **MongoDB** | SSPL* | ⚠️ Review required | Conditional (verified compliance) |
| **TensorFlow.js** | Apache 2.0 | ✅ Compatible | Approved |
| **Prisma** | Apache 2.0 | ✅ Compatible | Approved |
| **Jest** | MIT | ✅ Compatible | Approved |

*SSPL (Server-Side Public License) has restrictions on commercial cloud deployment; verified institutional use acceptable.

#### 2.6.4 GitHub Repository Structure

**Main Repositories:**
1. **frontend** (Client code): `https://github.com/[team]/adaptive-ai-learn-client`
2. **backend** (Server code): `https://github.com/[team]/adaptive-ai-learn-server`
3. **documentation** (Docs): `https://github.com/[team]/adaptive-ai-learn-docs`

See Section 3 for complete repository links.

#### 2.6.5 Deployment Restrictions

**Deployment Platforms Used:**
- ✅ Netlify (frontend) — free tier
- ✅ Heroku/Railway (backend) — free/low-cost
- ✅ MongoDB Atlas (database) — free tier
- ✅ GitHub (code hosting) — free

**Platforms Not Used Due to Licensing:**
- ❌ Proprietary cloud services with restrictive terms
- ❌ Platforms requiring commercial licenses
- ❌ Services with data sovereignty concerns

#### 2.6.6 Phase 2 Deployment Recommendations

- Professional hosting (AWS/Azure/GCP) for production
- Verify licensing compliance for production deployment
- Establish open-source governance (contributors guide, PR review)
- Plan for community contributions and maintenance

---

### 2.7 Maintenance and Sustainability Constraints

#### 2.7.1 Description

Technology choices were made to prioritize **long-term maintainability** and use only actively-maintained, well-supported technologies.

#### 2.7.2 Technology Selection Criteria

**Requirements for Technology Adoption:**
1. ✅ Active maintenance (releases within past 6 months)
2. ✅ Large community support (10k+ GitHub stars or equivalent)
3. ✅ Stable API (major version 1.0+)
4. ✅ Clear upgrade path for future versions
5. ✅ No planned deprecation

#### 2.7.3 Technologies Chosen for Longevity

| Technology | Maintenance Status | Support Level | Decision |
|-----------|-------------------|--------------|----------|
| **Node.js 18 LTS** | ✅ Active (LTS until 2025) | Enterprise-grade | Long-term support guaranteed |
| **React 18** | ✅ Active monthly releases | Meta-supported | Large ecosystem; stable |
| **Express.js** | ✅ Active maintenance | Community-supported | Mature framework; low churn |
| **MongoDB** | ✅ Enterprise backing | Commercial support available | Stable; good support |
| **TensorFlow.js** | ✅ Google-backed | Enterprise-grade | Backed by Google; long-term |

#### 2.7.4 Technologies Avoided Due to Maintenance Concerns

| Technology | Reason for Rejection |
|-----------|-------------------|
| **Meteor.js** | Declining community; irregular updates |
| **Ember.js** | Smaller ecosystem; uncertain future |
| **Older ML libraries** | No GPU support; outdated models |
| **Custom ORM** | Would require ongoing maintenance burden |
| **Emerging frameworks** | Too immature; uncertain longevity |

#### 2.7.5 Technical Debt and Sustainability

**Current State (After MVP):**
- Code quality: Good (75% test coverage)
- Documentation: Comprehensive (architecture + API docs)
- Dependency versions: Current (updated as of Jan 2026)
- Vulnerability scan: No high-severity issues

**Future Maintenance Plan:**
- Quarterly security audits
- Biannual dependency updates
- Annual architecture review
- Community contribution management

#### 2.7.6 Long-Term Support Commitment

- ✅ Open-source repository maintained for 5+ years
- ✅ Bug fixes for all reported issues
- ✅ Security patches applied immediately
- ✅ Community contributions accepted and reviewed

---

### 2.8 Team Competency Constraints

#### 2.8.1 Description

The project was developed by an **academic team of 6 computer science students** with varying expertise levels, which influenced technology choices and feature prioritization.

#### 2.8.2 Team Composition and Skills

**Team Members (Assigned Subsystems):**

| Name | Role | Expertise | Subsystem | Constraint |
|------|------|-----------|-----------|-----------|
| **Sam** | QA Lead | Testing, QA | Assessment Engine (4.3) | Limited ML knowledge |
| **Pakhlavon** | Lead Dev | Algorithms, ML | Learning Path (4.2) | Scarce ML infrastructure expertise |
| **Övgü** | Product Manager | Architecture | User & Identity (4.1) | No OAuth experience initially |
| **Zerda** | Content Engineer | Backend | Content Management (4.4) | Database optimization needed |
| **Semiha** | Analytics Dev | Data, DB | Analytics (4.5) | Limited dashboard design experience |
| **Serenay** | Frontend Dev | React, UI | Notifications (4.6) | Backend coordination challenging |

#### 2.8.3 Skills Gaps and Mitigation

**Gap #1: Machine Learning Operations (ML Ops)**
- **Constraint:** No team member had ML Ops experience
- **Features Affected:** Automated model retraining, continuous deployment
- **Mitigation:** Manual ML ops processes; deferred automated pipeline to Phase 2
- **Decision:** Prioritize model accuracy over operational automation

**Gap #2: Advanced NLP / Speech Processing**
- **Constraint:** No team member specialized in NLP
- **Features Affected:** Open-ended response grading, pronunciation analysis
- **Mitigation:** Used rule-based approaches; teacher review fallback
- **Decision:** Built extensible NLP interface for future upgrades

**Gap #3: OAuth / Identity Management**
- **Constraint:** No prior OAuth implementation experience
- **Solution Strategy:** Used well-documented libraries and examples
- **Outcome:** Successfully implemented; learned on the job

**Gap #4: DevOps / Cloud Infrastructure**
- **Constraint:** Limited DevOps expertise
- **Mitigation:** Used managed services (MongoDB Atlas) vs. self-hosted
- **Decision:** Prioritize ease of deployment over optimization

#### 2.8.4 Impact on Architecture

**Simplifications Made Due to Team Skills:**

| Area | Original Plan | Simplified Implementation | Reason |
|------|--------------|-------------------------|--------|
| **ML Models** | Deep learning ensembles | Collaborative filtering + mastery modeling | Team expertise limit |
| **Architecture** | Microservices | Monolith with clear service layers | Deployment complexity |
| **DevOps** | CI/CD pipeline | Manual deployment with scripts | DevOps expertise unavailable |
| **NLP** | Advanced semantic analysis | Rule-based + teacher review | NLP expertise unavailable |
| **Database** | Complex normalized schema | Document DB with denormalization | Database design complexity |

#### 2.8.5 Upskilling Investments

**Training and Professional Development:**
- ✅ 2 team members completed TensorFlow.js online course
- ✅ 1 member completed OAuth security course
- ✅ 3 members completed advanced testing methodologies
- ✅ All 6 members completed Git/GitHub advanced workflows

**Impact:** Team improved significantly; Phase 2 will progress faster

#### 2.8.6 Phase 2 Recommendations

- Hire ML Ops specialist (part-time consultant) for automated pipelines
- Bring in NLP specialist for advanced grading
- Dedicate 1 person to DevOps/infrastructure
- Establish internal knowledge sharing on advanced topics

---

### 2.9 License and Copyright Constraints

#### 2.9.1 Description

The project uses only **open-source licenses** and avoids proprietary software or copyrighted materials, ensuring academic integrity and free distribution.

#### 2.9.2 Open-Source License Compliance

**Project License:**
- **Adaptive AI Learn:** MIT License (Permissive, allows commercial use)
- **GitHub:** Publicly accessible, open-source
- **Attribution:** Required for all derivative works

**Dependency Licenses Verified:**

```
✅ MIT License (Permissive)
- Node.js, Express.js, React, Jest, TensorFlow.js, Prisma, Mongoose, etc.
- Compatible with MIT project license

✅ Apache 2.0 License (Permissive with Patent Grant)
- TensorFlow.js, Prisma, many Google libraries
- Compatible with MIT project license

✅ SSPL License (Server-Side Public License)
- MongoDB: Conditional use verified for institutional non-commercial use
- Compliant with academic deployment

✅ ISC License (Permissive)
- npm packages: ISC compatible with MIT
- No conflicts identified
```

#### 2.9.3 No Proprietary or Pirated Software

**Verified:**
- ✅ All development tools are open-source or free tier (VS Code, Git, Node.js)
- ✅ No commercial software licenses required
- ✅ No cracked or pirated software used
- ✅ All libraries are properly licensed and documented

**Copyright Considerations:**
- ✅ Educational content created by authors; no copyrighted materials
- ✅ Sample data generated (not from real copyrighted sources)
- ✅ Icons from open-source icon libraries (Feather Icons, Font Awesome)
- ✅ Proper attribution included for all borrowed code/assets

#### 2.9.4 Third-Party Libraries Audit

**Libraries with Special Attention:**

| Library | License | Concern | Resolution |
|---------|---------|---------|-----------|
| **TensorFlow.js** | Apache 2.0 | Patent grant terms | Reviewed; acceptable for academic use |
| **MongoDB** | SSPL | Commercial deployment | Verified compliance for institutional use |
| **React** | MIT | Meta-governed | Stable governance; no concerns |

#### 2.9.5 GitHub Repository License File

```
# Adaptive AI Learn - MIT License

MIT License (c) 2025-2026 Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

#### 2.9.6 Phase 2 Licensing

- Maintain MIT license for open-source distribution
- Evaluate proprietary licenses only if commercial version planned
- Continue regular license compliance audits
- Establish contributor agreement (CLA) for community contributions

---

---

## 3. GITHUB PROJECT REPOSITORY LINKS

### 3.1 Primary Repository Links

The complete Adaptive AI Learn project is distributed across three primary repositories on GitHub:

#### 3.1.1 Backend Repository
**Repository Name:** `adaptive-ai-learn-server`  
**URL:** `https://github.com/[team-org]/adaptive-ai-learn-server`  
**Visibility:** Public  
**Branch:** `main` (production-ready code)

**Contents:**
- Node.js/Express backend server code
- Prisma ORM and database models
- ML recommendation engine implementation
- Assessment engine logic
- Analytics service
- Authentication and RBAC implementation
- API endpoints documentation (Swagger/OpenAPI)

**Key Directories:**
```
/server
├── /src
│   ├── /models           (Database models)
│   ├── /services         (Business logic)
│   ├── /controllers      (API endpoints)
│   ├── /middleware       (Auth, validation)
│   ├── /ml              (ML models & training)
│   └── /analytics       (Reporting service)
├── /scripts             (Database seed, utilities)
├── /tests               (Unit & integration tests)
├── package.json         (Dependencies)
└── README.md            (Setup instructions)
```

**Setup Instructions Included:**
- Environment configuration (.env)
- Database initialization
- Dependency installation
- Running development server
- Running test suite

---

#### 3.1.2 Frontend Repository
**Repository Name:** `adaptive-ai-learn-client`  
**URL:** `https://github.com/[team-org]/adaptive-ai-learn-client`  
**Visibility:** Public  
**Branch:** `main` (production-ready code)

**Contents:**
- React 18 frontend application
- Component library (Learning interface, Dashboard, etc.)
- UI styling and responsive design
- Service worker (offline support)
- API integration layer
- Authentication UI flows
- Accessibility features

**Key Directories:**
```
/client
├── /src
│   ├── /components      (React components)
│   ├── /pages          (Page components)
│   ├── /hooks          (Custom React hooks)
│   ├── /api            (API client services)
│   ├── /utils          (Utilities & helpers)
│   ├── /styles         (CSS & styling)
│   └── /assets         (Images, icons)
├── /public             (Static assets)
├── vite.config.js      (Build configuration)
├── package.json        (Dependencies)
└── README.md           (Setup instructions)
```

**Setup Instructions Included:**
- Node.js version requirements
- Dependency installation
- Development server startup
- Build process
- Deployment instructions

---

#### 3.1.3 Documentation Repository (Optional)
**Repository Name:** `adaptive-ai-learn-docs`  
**URL:** `https://github.com/[team-org]/adaptive-ai-learn-docs`  
**Visibility:** Public  
**Branch:** `main` (documentation)

**Contents:**
- Software requirements specification (SRS)
- System architecture documentation
- API documentation
- User guides
- Developer guides
- Testing documentation (THIS FILE)
- Deployment guides

**Documentation Files:**
- `README.md` — Project overview
- `ARCHITECTURE.md` — System design
- `API_DOCUMENTATION.md` — REST API reference
- `USER_GUIDE.md` — Student/teacher guide
- `DEVELOPER_GUIDE.md` — Development setup
- `TESTING_GUIDE.md` — Test case documentation
- `DEPLOYMENT.md` — Production deployment
- `CONSTRAINTS.md` — This constraints document

---

### 3.2 Repository Access and Permissions

**Access Level:** Public (No special permissions required)

- All repositories are publicly accessible on GitHub
- Clone commands work without authentication:
  ```bash
  git clone https://github.com/[team-org]/adaptive-ai-learn-server.git
  git clone https://github.com/[team-org]/adaptive-ai-learn-client.git
  ```

**Contributing:**
- Pull requests accepted from community
- Issues can be filed publicly
- Contributor license agreement (CLA) required for non-trivial contributions

---

### 3.3 Repository Statistics

| Metric | Backend | Frontend | Documentation |
|--------|---------|----------|---------------|
| **Total Commits** | 120+ | 95+ | 50+ |
| **Contributors** | 6 | 6 | 6 |
| **Code Lines** | ~8,000 | ~6,500 | ~15,000 |
| **Test Coverage** | 75% | 68% | N/A |
| **Last Updated** | January 15, 2026 | January 15, 2026 | January 15, 2026 |
| **Releases** | v1.0.0 (MVP) | v1.0.0 (MVP) | v1.0.0 |

---

### 3.4 Complete Installation Guide

**Quick Start - Clone and Run:**

```bash
# Clone repositories
git clone https://github.com/[team-org]/adaptive-ai-learn-server.git
git clone https://github.com/[team-org]/adaptive-ai-learn-client.git

# Backend setup
cd adaptive-ai-learn-server
npm install
cp .env.example .env          # Configure environment
npm run db:init              # Initialize database
npm run dev                  # Start development server

# Frontend setup (in new terminal)
cd adaptive-ai-learn-client
npm install
npm run dev                  # Start development server

# Access application
# Frontend: http://localhost:5173
# Backend: http://localhost:3000
```

**Complete documentation available in each repository README**

---

### 3.5 Additional Resources

**Project Website (if available):**
- Documentation hub: `https://[project-docs-site]` (planned for Phase 2)
- Live demo: `https://adaptive-ai-learn.example.com` (staging deployment)

**Related Links:**
- Faculty project page: [University link]
- Capstone presentation: [Link to demo]
- Academic paper: [If published]

---

---

## 4. LESSONS LEARNED & RECOMMENDATIONS FOR FUTURE PHASES

### 4.1 What Worked Well

**Decisions That Accelerated Development:**

1. ✅ **Clear Scope Definition**
   - Defined MVP scope early; prevented feature creep
   - Enabled parallel subsystem development
   - Result: Delivered on time

2. ✅ **Technology Stack Simplification**
   - Chose familiar technologies (Node.js, React)
   - Avoided complex architectures (microservices)
   - Result: Faster development, fewer integration issues

3. ✅ **Comprehensive Testing from Start**
   - Automated testing identified issues early
   - 75% test coverage caught bugs before production
   - Result: High confidence in code quality

4. ✅ **Agile Methodology**
   - 1-week sprints with daily standups
   - Rapid feedback loops
   - Result: Adaptable to changes, good team communication

5. ✅ **Open-Source Approach**
   - Transparent development
   - Community standards and best practices
   - Result: Code quality, maintainability

### 4.2 What Was Challenging

**Areas That Needed More Attention:**

1. ⚠️ **ML Model Development**
   - Limited ML expertise on team
   - Model training/validation time-consuming
   - Recommendation: Hire ML specialist for Phase 2

2. ⚠️ **Cross-Subsystem Integration**
   - 6 parallel subsystems created coordination overhead
   - API contract mismatches discovered late
   - Recommendation: Establish API contracts earlier (OpenAPI specs)

3. ⚠️ **Performance Optimization**
   - Performance testing deferred to late stage
   - Optimization difficult after implementation
   - Recommendation: Performance benchmarks from start

4. ⚠️ **Documentation Maintenance**
   - Documentation lagged behind code changes
   - Final documentation sprint intense
   - Recommendation: Documentation-as-code approach

### 4.3 Recommendations for Phase 2

#### 4.3.1 Team & Resources

- **Hire 1 ML Ops specialist** (part-time consultant)
- **Hire 1 NLP specialist** (contract) for advanced grading
- **Dedicate 1 DevOps engineer** for infrastructure scaling
- **Expand QA team** from 1 to 2 members for phase complexity

#### 4.3.2 Architecture & Technical Improvements

- **Implement CI/CD Pipeline:** Automated testing and deployment
- **Add Monitoring & Observability:** Datadog/New Relic setup
- **Scale Infrastructure:** Multi-region deployment, CDN
- **Optimize Database:** Query optimization, sharding strategy
- **Advanced ML Ops:** Model versioning, A/B testing framework

#### 4.3.3 Feature Prioritization for Phase 2

**High Priority (Weeks 1-4):**
1. LMS integration (Canvas API)
2. Advanced teacher dashboard
3. Automated model retraining

**Medium Priority (Weeks 5-8):**
4. Advanced NLP grading
5. Mobile push notifications
6. Performance optimization

**Lower Priority (Weeks 9-12):**
7. Advanced speaking module
8. Custom report builder
9. Third-party integrations

#### 4.3.4 Quality Improvements

- Increase test coverage from 75% to 85%+
- Implement performance testing framework
- Security penetration testing
- Load testing up to 1000 concurrent users
- User acceptance testing (UAT) with real educators

#### 4.3.5 Documentation & Knowledge

- Establish API documentation maintenance process
- Create architecture decision records (ADRs)
- Build internal knowledge base
- Develop contributor guide for community contributions

### 4.4 Risk Mitigation for Phase 2

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|-----------|
| **Scope Creep** | High | High | Strict change control; separate Phase 3 backlog |
| **Performance Degradation** | Medium | High | Performance testing sprint 1; monitoring setup |
| **Integration Complexity** | Medium | Medium | API contract tests; integration tests daily |
| **Data Scale Issues** | Medium | Medium | Database sharding plan; data volume tests |
| **Team Attrition** | Low | High | Knowledge documentation; cross-training |

### 4.5 Success Metrics for Phase 2

**Technical Metrics:**
- System handles 500+ concurrent users (target: NFR2)
- Path generation latency < 200ms (target: NFR5)
- System uptime 99.95% (target: NFR3)
- Test coverage 85%+
- Zero critical security vulnerabilities

**Business Metrics:**
- 3+ LMS integrations completed
- 500+ beta users in pilot schools
- 95%+ user satisfaction (NPS > 50)
- 90%+ feature adoption rate

**Team Metrics:**
- All 6 core features complete
- Knowledge transfer documentation complete
- Zero team member involuntary attrition
- Community contributions received (GitHub issues resolved)

---

---

## APPENDIX A: Constraint Summary Matrix

| Constraint Category | Severity | Impact on Project | Mitigation Status |
|-------------------|----------|------------------|------------------|
| **Time Constraints** | High | Reduced feature scope, deferred Phase 2 | ✅ Managed |
| **Budget Constraints** | High | Free-tier only, limited APIs | ✅ Accepted |
| **Hardware Constraints** | Medium | Simplified ML models | ✅ Acceptable |
| **Platform Constraints** | Medium | Web-only, no mobile native | ✅ Strategic choice |
| **Privacy Constraints** | High | Reduced personalization data | ✅ By design |
| **Deployment Constraints** | Low | Open-source only | ✅ Preferred |
| **Maintenance Constraints** | Medium | Technology choices prioritized longevity | ✅ Excellent |
| **Team Competency Constraints** | Medium | Simplified architecture, deferred complex features | ✅ Mitigated |
| **Licensing Constraints** | Low | All dependencies open-source compliant | ✅ Verified |

---

## APPENDIX B: Functional Requirement Traceability

| Feature ID | Feature Name | Implementation Status | Reason if Incomplete | Phase 2 Plan |
|-----------|-------------|----------------------|-------------------|------------|
| FR1 | User Registration | ✅ Complete | — | — |
| FR2 | User Role Management | ✅ Complete | — | — |
| FR3 | Achievement Badges | ✅ Basic | Points system only | Advanced gamification |
| FR4 | Dynamic Learning Path | ⚠️ Partial | Single-path only | Multi-path options |
| FR5 | Adaptive Lessons | ✅ Complete | — | — |
| FR6 | Adaptive Assessments | ✅ Complete | — | — |
| FR7 | NLP Open-Ended Feedback | ⚠️ Partial | Rule-based only | Advanced semantic analysis |
| FR8 | Knowledge Gap Identification | ✅ Complete | — | — |
| FR9 | Enrichment Recommendations | ✅ Complete | — | — |
| FR10 | Teacher Dashboard | ⚠️ Partial | Basic analytics only | Advanced dashboards |
| FR11 | Multi-Language Support | ⚠️ Partial | 3 languages only | 10+ languages + RTL |
| FR12 | Schedule Lessons | ⚠️ Partial | Basic only | Calendar UI + integration |
| FR13 | Export Reports | ✅ Complete (PDF/CSV) | — | PowerPoint export |
| FR14 | Audit Logging | ✅ Complete | — | — |
| FR15 | Notifications | ⚠️ Partial | Email + in-app only | SMS + push notifications |
| FR16 | Model Retraining | ⚠️ Partial | Manual process only | Automated ML Ops |
| FR17 | RBAC | ✅ Complete | — | — |
| FR18 | Offline Support | ✅ Partial | Cached content only | Full offline experience |
| FR19 | Data Privacy Controls | ✅ Complete | — | — |
| FR20 | OAuth Integration | ✅ Complete | Google only | Multiple providers |
| FR21 | Support Contact Form | ✅ Complete | — | — |
| FR22 | Speaking Module | ⚠️ Partial | Voice input only | Pronunciation analysis |
| FR23 | Listening Module | ⚠️ Partial | Basic playback | Advanced listening features |

---

## APPENDIX C: Constraint Impact Timeline

```
Phase 1 (MVP Development) — September - January 2026
├─ Time Constraint: Semester deadline drives scope reduction
├─ Budget Constraint: Free-tier only; impacts APIs selected
├─ Team Competency: Limits ML complexity, architecture choices
├─ Platform Constraint: Web-only decision made early
└─ Privacy Constraint: GDPR/KVKK compliance designed in

Phase 2 (Integration & Enhancement) — February - June 2026
├─ Infrastructure upgrades needed (GPU, scaling)
├─ Budget increase assumed ($3,000/month)
├─ Hiring planned (ML Ops, NLP specialist)
├─ Mobile platform expansion considered
└─ Advanced features implemented (LMS, advanced NLP)

Phase 3+ (Production & Beyond)
├─ Commercial licensing decisions
├─ Enterprise deployment considerations
├─ Additional language/platform support
└─ Long-term maintenance planning
```

---

## SIGN-OFF

**Document Prepared By:** Quality Assurance Team (Sam)  
**Document Date:** January 15, 2026  
**Status:** ✅ FINAL

**Reviewed By:**
- Pakhlavon (Learning Path Lead)
- Övgü (Product Manager)
- Zerda, Semiha, Serenay (Subsystem Leads)

**Approved for Distribution:** ✅ Yes

This document comprehensively documents all constraints and unimplemented requirements for the Adaptive AI Learn project MVP, providing transparency and setting realistic expectations for faculty advisors and stakeholders.

---

**END OF CONSTRAINTS AND UNIMPLEMENTED REQUIREMENTS DOCUMENT**

*For questions about constraints, contact the Product Manager (Övgü) or QA Lead (Sam).*
